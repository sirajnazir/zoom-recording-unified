const { EnhancedProcessorWithDownloads } = require('./enhanced-processor-with-downloads');
const { Logger } = require('./src/shared/Logger');

/**
 * Integration example: Using enhanced downloads with existing processor
 */
async function integrateEnhancedDownloads() {
    const logger = new Logger('EnhancedDownloadIntegration');
    
    console.log('üîß Enhanced Download Integration Example');
    console.log('========================================');

    // Example 1: High-speed processing for large batches
    console.log('\nüìä Example 1: High-Speed Parallel Processing');
    console.log('----------------------------------------------');
    
    const highSpeedProcessor = new EnhancedProcessorWithDownloads({
        // Enhanced processor settings
        maxConcurrent: 4,
        batchSize: 20,
        resumeFromFile: './high-speed-progress.json',
        skipDuplicates: true,
        cleanupAfterUpload: true,
        
        // NEW: High-performance download settings
        useParallelDownloads: true,
        useStreamingDownloads: false,
        downloadConcurrency: 8,
        downloadTimeout: 600000, // 10 minutes
        enableResumeDownloads: false // Not needed for parallel
    });

    // Set up event listeners for monitoring
    highSpeedProcessor
        .on('processingStart', (data) => {
            logger.info(`üöÄ Starting high-speed processing of ${data.totalRecordings} recordings`);
        })
        .on('downloadProgress', (data) => {
            if (data.type === 'parallel') {
                const mbDownloaded = (data.bytesDownloaded / 1024 / 1024).toFixed(2);
                const speed = (data.speed / 1024 / 1024).toFixed(2);
                logger.info(`üì• ${data.filename}: ${mbDownloaded} MB (${speed} MB/s)`);
            }
        })
        .on('recordingDownloaded', (data) => {
            logger.info(`‚úÖ Downloaded ${data.recordingId} using ${data.method}`);
        })
        .on('processingComplete', (data) => {
            logger.info(`üéâ High-speed processing completed!`);
            logger.info(`üìà Stats: ${data.processed}/${data.total} successful (${data.successRate.toFixed(1)}%)`);
            logger.info(`‚è±Ô∏è  Duration: ${(data.duration / 1000 / 60).toFixed(1)} minutes`);
        });

    // Example 2: Reliable processing with resume capability
    console.log('\nüìä Example 2: Reliable Processing with Resume');
    console.log('----------------------------------------------');
    
    const reliableProcessor = new EnhancedProcessorWithDownloads({
        // Enhanced processor settings
        maxConcurrent: 2,
        batchSize: 5,
        resumeFromFile: './reliable-progress.json',
        skipDuplicates: true,
        cleanupAfterUpload: false, // Keep files for safety
        
        // NEW: Reliable download settings
        useParallelDownloads: false,
        useStreamingDownloads: true,
        downloadConcurrency: 3,
        downloadTimeout: 900000, // 15 minutes
        enableResumeDownloads: true // Enable resume capability
    });

    reliableProcessor
        .on('processingStart', (data) => {
            logger.info(`üõ°Ô∏è  Starting reliable processing of ${data.totalRecordings} recordings`);
        })
        .on('downloadStart', (data) => {
            if (data.type === 'streaming') {
                logger.info(`üì• Starting reliable download: ${data.filename}`);
            }
        })
        .on('downloadProgress', (data) => {
            if (data.type === 'streaming') {
                logger.info(`üìä ${data.filename}: ${data.progress.toFixed(1)}% (${(data.speed / 1024 / 1024).toFixed(2)} MB/s)`);
            }
        })
        .on('processingComplete', (data) => {
            logger.info(`üõ°Ô∏è  Reliable processing completed!`);
            logger.info(`üìà Stats: ${data.processed}/${data.total} successful (${data.successRate.toFixed(1)}%)`);
        });

    // Example 3: Hybrid approach - best of both worlds
    console.log('\nüìä Example 3: Hybrid Processing Strategy');
    console.log('----------------------------------------');
    
    const hybridProcessor = new EnhancedProcessorWithDownloads({
        // Enhanced processor settings
        maxConcurrent: 3,
        batchSize: 10,
        resumeFromFile: './hybrid-progress.json',
        skipDuplicates: true,
        cleanupAfterUpload: true,
        
        // NEW: Hybrid download settings
        useParallelDownloads: true,  // Use parallel for speed
        useStreamingDownloads: true, // Fallback to streaming if parallel fails
        downloadConcurrency: 6,
        downloadTimeout: 600000,
        enableResumeDownloads: true
    });

    hybridProcessor
        .on('processingStart', (data) => {
            logger.info(`‚ö° Starting hybrid processing of ${data.totalRecordings} recordings`);
        })
        .on('recordingDownloaded', (data) => {
            logger.info(`‚úÖ ${data.recordingId} downloaded using ${data.method}`);
        })
        .on('recordingDownloadError', (data) => {
            logger.warn(`‚ö†Ô∏è  ${data.recordingId} failed, will retry with different method`);
        })
        .on('processingComplete', (data) => {
            logger.info(`‚ö° Hybrid processing completed!`);
            logger.info(`üìà Stats: ${data.processed}/${data.total} successful (${data.successRate.toFixed(1)}%)`);
        });

    // Usage examples with your existing recordings
    console.log('\nüí° Usage Examples with Your Data');
    console.log('=================================');
    
    // Example: Process your 324 recordings with different strategies
    const exampleRecordings = [
        // Your actual recordings would go here
        // { uuid: '...', download_url: '...', topic: '...', start_time: '...' }
    ];

    console.log('\n1Ô∏è‚É£  High-Speed Processing (for fast internet):');
    console.log('   const processor = new EnhancedProcessorWithDownloads({');
    console.log('     useParallelDownloads: true,');
    console.log('     downloadConcurrency: 8,');
    console.log('     maxConcurrent: 4');
    console.log('   });');
    console.log('   await processor.processRecordings(recordings, { outputDir: "./downloads" });');

    console.log('\n2Ô∏è‚É£  Reliable Processing (for unstable connections):');
    console.log('   const processor = new EnhancedProcessorWithDownloads({');
    console.log('     useStreamingDownloads: true,');
    console.log('     enableResumeDownloads: true,');
    console.log('     downloadConcurrency: 3');
    console.log('   });');
    console.log('   await processor.processRecordings(recordings, { outputDir: "./downloads" });');

    console.log('\n3Ô∏è‚É£  Hybrid Processing (best of both):');
    console.log('   const processor = new EnhancedProcessorWithDownloads({');
    console.log('     useParallelDownloads: true,');
    console.log('     useStreamingDownloads: true,');
    console.log('     enableResumeDownloads: true');
    console.log('   });');
    console.log('   await processor.processRecordings(recordings, { outputDir: "./downloads" });');

    console.log('\nüéØ Key Benefits:');
    console.log('================');
    console.log('‚úÖ Maintains all existing functionality');
    console.log('‚úÖ Adds 8x faster parallel downloads');
    console.log('‚úÖ Adds resume capability for reliability');
    console.log('‚úÖ Automatic fallback strategies');
    console.log('‚úÖ Progress tracking and statistics');
    console.log('‚úÖ Configurable for different network conditions');

    console.log('\nüöÄ Ready to process your 324 recordings with enhanced performance!');
}

// Export for use in other scripts
module.exports = { integrateEnhancedDownloads };

// Run if called directly
if (require.main === module) {
    integrateEnhancedDownloads().catch(console.error);
} 